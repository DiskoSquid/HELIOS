After the initial steps from the guide (https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md):

git clone "repo link"
sudo apt-get update && sudo apt-get upgrade


virtual environment has been created to store the TFlight model, to prevent the version conflicts
if, for instance, one would like to install another version of TF on the same machine,
not to mess up current model.

sudo pip3 install virtualenv
python3.7 -m venv TFLite-venv
bash get_py_requirements.sh

Every time, if the terminal session has ended, virtual environment needs to be started by moving to the directory 
which has been used for the installation (in this case: ~/THEIA/objectDetTFLight/tflite1) and issuing a command: source TFLite-venv/bin/activate
This is a working environment that will be used for the rest of the document.
There is a nice bash script in the repo called get_pi_requirements.sh that also has a good if clause which
uses different installer depending on the version of the dependency it finds. Run it: bash  get_pi_requirements.sh
After that, there are two options: use a sample, already trained model or train and use your own. Each model is stored in a folder
that has detect file (which stores the model) and the label map file (storing the labels).
First, google's sample model has been tested:

wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip

unzip coco_ssd_mobilenet_v1_1.0_quant_2018_06_29.zip -d Sample_TFLite_model

To run it, use: python3 TFLite_detection_webcam.py --modeldir=Sample_TFLite_model

It uses a a really robust python script that utilizes either PI cam or regular usb camera, meaning it can be recycled for future projects.
If one wants to use custom model, change the name in the previous command to the folder of the custome model. One can also use two other scripts
that can process already recorded video or a set of images. This is basically, remote development.

python3 TFLite_detection_video.py --modeldir="input the model folder here" --video="input the video name here with the .format (.mp4 for example)"

python3 TFLite_detection_image.py --modeldir="input the model folder here" --imagedir="input folder with the pictures"
python3 TFLite_detection_webcam.py --modeldir=Sample_TFLite_model

To speed up the detection, one can also use Coral USB Accelerator, whose use has also been documented.
