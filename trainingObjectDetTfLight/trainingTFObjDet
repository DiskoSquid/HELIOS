12.02.2021, training TF models using Object Detection API (TF OD API), which is an OS framework built on top of the TF,
which makes it easier to contruct, train and deploy object detection models.
TF2 OD API can be converted to TF Lite, but only SSD models are currently supported:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md

To install it, use info on: 

https://anaconda.org/conda-forge/tf_object_detection
https://github.com/tensorflow/models/tree/master/research/object_detection

One can either use API to train and deploy a customized model or make statistical inference using pre-trained models from the model ZOO

Link below provides extensive documentation on how to use the API, configure the object detection pipeline and prepare inputs:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2.md

Git repo had been cloned into the docker image, installed and tested. See documentationTFDockerSetup.txt for details

Faster R-CNN models are better suited to cases where high accuracy is desired and latency is of lower priority. 
Conversely, if processing time is the most important factor, SSD models are recommended. 

Training and Evaluation of the model:

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md

First, a valid data set has to be created. TensorFlow Object Detection API reads data using the TFRecord file format.
Recycling the flow from the 
https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10
and
https://github.com/tensorflow/models/tree/079d67d9a0b3407e8d074a200780f3835413ef99

a generatTfRecord tool was first created, now part of the HELIOS Tools set.
Label the images and split them and their adjecent xml files in the images/train and images/test directories in the generateTfRecord tool folder.
Then run the xml_to_csv.py script.

Open generate_tfrecord.py and replace the label map that starts with the line 31 with the one used for this training data set, in this case, 
of only one object detection it looks like:

def class_text_to_int(row_label):
    if row_label == 'Object':
        return 1
    else:
        None

Additional case, deck of cards recognition:

def class_text_to_int(row_label):
    if row_label == 'nine':
        return 1
    elif row_label == 'ten':
        return 2
    elif row_label == 'jack':
        return 3
    elif row_label == 'queen':
        return 4
    elif row_label == 'king':
        return 5
    elif row_label == 'ace':
        return 6
    else:
        None


Create record files:
python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=train.record
python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=test.record

Last steps before training are creation of the label map and editing the config file.
Create labelmap.pbtxt file in the object_detection/data, or edit the existing one
to match the label map in generate_tfrecord.py

In the simplest case, it is just a file with this text:

item {
  id: 1
  name: 'Object'
}

With this, data set is prepared.


Model just needs to be configured using the config file. The config file calls the models from the installed models from the repo.

https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md  This is how config is made

Following the instructions, one must now organize the folders. Inside the object_detection/models folder, create a directory with the 
name of the desired model, in this case HELIOS_1. 
Inside the directory, copy the .config file from object_detection/samples, or one that was downloaded with the checkpoint values:
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

Place the contents inside the HELIOS_1

Make the following changes to the config file of the desired model, usually labeled with pipeline.config


num_classes: 1 

train_config {
  batch_size: 6

 fine_tune_checkpoint: "/home/theia/_data/tfModels/models/research/object_detection/models/HELIOS_1/ckpt-0"

eval_input_reader {
  label_map_path: "/home/theia/_data/tfModels/models/research/object_detection/data/labelmap.pbtxt"
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: "/home/theia/_data/tfModels/models/research/object_detection/test.record"
  }


}
train_input_reader {
  label_map_path: "/home/theia/_data/tfModels/models/research/object_detection/data/labelmap.pbtxt"
  tf_record_input_reader {
    input_path: "/home/theia/_data/tfModels/models/research/object_detection/data/train.record"
  }







Inside the object_detection/data folder, copy the created train and test .record files. labelmap.pbtxt must also be there.

# From the tensorflow/models/research/ directory

PIPELINE_CONFIG_PATH=object_detection/models/HELIOS_1/pipeline.config

MODEL_DIR=PIPELINE_CONFIG_PATH=object_detection/models/HELIOS_1

python object_detection/model_main_tf2.py \
    --pipeline_config_path=${PIPELINE_CONFIG_PATH} \
    --model_dir=${MODEL_DIR} \
    --alsologtostderr


